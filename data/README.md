<div align="left"><img src="https://raw.githubusercontent.com/EconomicsObservatory/ECOvisualisations/main/guidelines/logos/eco-bg-dark.png" width="800"/></div>

# ‚ú® The language of (economic) data is visualisation ‚ú® 
An interactive masterclass by the **Economics Observatory**

[![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/EconomicsObservatory/ecovisualisations/blob/main/LICENSE)

[**Website**](https://www.economicsobservatory.com/)
| <ins>[**Courses**](https://github.com/EconomicsObservatory/courses)</ins>
| [**Visualisations**](https://github.com/EconomicsObservatory/ECOvisualisations)
| [**Data**](https://github.com/EconomicsObservatory/ECOdataHUB)
| [**API**](https://github.com/EconomicsObservatory/api)
|

Welcome to our interactive data masterclass. At the **Economics Observatory** we believe that the future of effective science communication is a blend of data and text. Dashboards without context are too cluttered and text without explanatory graphics is difficult to grasp. Therefore, we have partnered with educators from leading institutions across teh country to be able to offer masterclasses in [Writing](/writing) and [Data](/data).

In our day-to-day work the **Economics Observatory**, we use data to amplify and distil the messages of our articles. Making charts clear and eye-catching, while also ensuring that the underlying data are transparent and replicable, is critical to what we do. This masterclass is designed to capture and share that workflow.

## üîç Scope

Our data visualisation masterclass will take you from a being complete beginner to someone capable of designing and building stunning charts using cutting-edge tools, connected to live data. The course is designed to highlight the advantages and some caveats of using data visualisation as the main channel for communicating (economic) information to a wide and diverse audience. It will also introduce some of our guiding principles on visualisation, focusing on transparency and how to select appropriate tools and methods for different datasets and contexts.

You will gain the skills and tools needed to create excellent charts. The course will also signpost additional resources to develop the ideas further, allowing participants to gain confidence in their own abilities and teach others. The latter stages of the course will delve deeper into the current information representation and science communication theory, exploring more advanced data visualisation methods.


## üïí Schedule
| Session |    Time     |                Topic                 |
| :-----: | :---------: | :----------------------------------: |
|    1    | 09:00-10:30 |     Building your first website      |
|  Break  | 10:30-11:00 |             Coffee break             |
|    2    | 11:00-12:30 |   Introduction to data processing    |
|  Break  | 12:30-13:30 |             Lunch break              |
|    3    | 13:30-15:00 |   Accessing data programmatically    |
|  Break  | 15:00-15:30 |             Coffee break             |
|    4    | 15:30-17:00 | Visualisation and advanced analytics |

## üìë Syllabus

### Session 1 - Building your first website

`Coordinated by: Prof Richard Davies`  
  
üîñ In the first session we introduce HTML, CSS and JavaScript as you build and style your first website. You will also embed your first automated and interactive charts.

#### a.	Introduction + building blocks

-	Motivation   
What is good Data Science? Where does it sit? Principles.
- Web building blocks: HTML, CSS and JS  
(visualisations are _just üåü fancy üåü websites_ built from components)
- Building your first interactive web site
- [GitHub](https://github.com/) pages
- Introduction 

#### b.	Charting principles
- The good the bad and the ugly
- History
- Good charting guide
- Making two live and interactive charts
- Introduction to charting libraries

#### üéÆ Action points

- ‚ñ∂Ô∏è Please watch [this introductory video](https://www.dropbox.com/s/b456p0m5iclhwo5/Data%20Science%20%28EFIM30006%29%20Set%20Up%20Video.mp4?dl=0)
- Set up your own [GitHub](https://github.com/) account at `username` and repository at `username.github.io`. For example, Richard‚Äôs account is `RDEconomist`, so his special repository is `RDEconomist.github.io`. Repositories are like an on-line folder and you can, in general, name them as you wish. But this is a special case, which must be exactly your username. This special repository becomes your website which GitHub hosts for you, *free of charge*. After taking these steps, your GitHub should look like [this](https://github.com/eco-demo-student).
- Create a demo `index.html` page in your repository and add 3 sentences about yourself.:
  -  Why are you here?
  -  What is your level experience?
  -  What would you like to learn?
-  You should end up with something like [this](https://eco-demo-student.github.io/).

### Session 2 - Introduction to data processing

`Coordinated by: Prof Richard Davies`  

üîñ The second session is an introduction to data processing,  devoted to loops, one of the most powerful tools in any coder‚Äôs arsenal and conditionality statements. We will show how a loop takes you from a small dataset to the world of big data.

#### a. Programming for Data Science

- Conditionality: `if` statements
- Iterations: `for` loops
- Multi-dimensional data
- Elegance in code

### Session 3 - Accessing data programmatically

`Coordinated by: Dr D√©nes Csala`  

üîñ In our third session we turn the coding up a notch and access data from the web - including websites but also dedicated data transfer interfaces - *API*s, discussing the benefits, pitfalls and debugging. Visualisations are the language of data for üßë‚Äçü¶≤ *humans*, while APIs are the language of data for ü§ñ *computers*.

#### a. Introduction to data formats

- `python`
  - `python` dictionaries and lists
  - `pandas` - not this one üêº, 
  but the excellent [`Python Data Analysis Library`](https://pandas.pydata.org/)
- `JavaScript`
  - `JSON` JavaScript Objects and Arrays

#### b. Automated data access üßô

- `ECO API` - the Economics Observatory's API
- Introductory web scraping with `pandas` `read_html`
- Advanced web scraping with `BeautifulSoup`
- Browser automation with `Selenium`

### Session 4 - Visualisation and advanced analytics

`Coordinated by: Dr D√©nes Csala`  

üîñ The last session of the day is an introduction to data visualisation principles and data models. We will also set some time aside to work on your personal data projects.

#### a.	The language of data ‚Äì the grammar of graphics

- Visual encodings
- The visualization zoo ü¶íü¶£ü¶òü¶•
  -  Introduction to chart types
  - Which chart to use when
- Data storytelling with interactive charts
- Basic principles of machine learning

#### b.	Data project

To finish off your course, you will work individualy or in small groups to create a data visualisation portfolio piece. You will be able to choose from a number of datasets, or you can bring your own data (see the **BYOD** section below). Our team be on hand to help you with any questions you might have.

Your finished portfolio should include a formatted and styled GitHub page with a short description of your project and 3 embedded visualisations. You will also be able to present your work to the rest of the class.  

You may end up with something like [this](https://economicsobservatory.github.io/courses/data/html/portfolio_sample/).

Ideally, your portfolio should include at least `3 charts`:
- One example chart that we used in the class, but has a slight modification and an interactive component - this could be a legend, a tooltip, a slider, a dropdown, etc.
-	A chart with automated data loading through an API or web scraping
-	A chart about a topic that you especially care about

#### üéÆ Action points

- Please think about what you might include in your portfolio and what data you might use. You can use any data you like, but we will also provide some datasets for you to use.
- If you would like to create a specific chart, we can help you build it - but consider the range of possibilities in the [Vega-Lite Example Gallery](https://vega.github.io/vega-lite/examples/). 

### Self-guided learning

This is an extra, self-guided session in which you will build tools to learn from the data. Using some guiding notebooks in `python`, we illustrate the differences between ****Artificial Intelligence**** (AI) and **Machine Learning** (ML) and the difference between *supervised* and *unsupervised* learning, as well as the use of labelled and unlabelled data.

### Resources

- [Heroes and heroines](https://www.playfairprize.com/william-playfair)   
Biographies of some key figures in data, past and present.
- [Nightingale Magazine](https://www.playfairprize.com/william-playfair)  
The publication of the [Data Visualization Society](https://www.datavisualizationsociety.org/)
  - [Finding the perfect blend of text and data](https://www.youtube.com/watch?v=eypYInYEVlA)  
    A talk by D√©nes Csala at the Data Visualization Society's Outlier 2023 Conference
- [MDN Starters guide](https://www.playfairprize.com/william-playfair)  
  A superb intro to HTML, CSS and JavaScript from [Mozilla](https://www.mozilla.org/en-US/?v=1).
- [W3Schools](https://www.w3schools.com/)  
  An equally superb intro to HTML, CSS and JavaScript from the [World Wide Web Consortium](https://www.w3.org/).

#### üî¥ ECO Visualisation Guidelines

Head over to our **[ECOvisualisations](https://github.com/EconomicsObservatory/ecovisualisations)** repository for all [Economics Observatory](https://www.economicsobservatory.com) charts sorted by article. We try to follow industry best-practices in data visualisation and try to establish our very own visualisation guidelines for all chart types. You can read about these, as well as the tools we use in [**üìêvisualisation guidelines**](https://github.com/EconomicsObservatory/ECOvisualisations/tree/main/guidelines).  

## üñáÔ∏è Pre-requisites
We don't require any prior knowledge of programming or data science, other than high-school level mathematics and statistics. However, it helps us speed up things on the day if you do some preparation before the class:

- Take a look at [Google Colab](https://colab.research.google.com/)
- Take a look at [Visual Studio Code (*VSCode*) Online](https://vscode.dev/)

#### üéÆ Action points

- Set up a [*Google* account](https://accounts.google.com/signup/v2/createaccount)  
  If you already have a *Google* account, but would be using using *Colab* for the first time, you will need to accept their specific terms and conditions for *Colab*. You can do this after setting up a [new workbook in *Colab*](https://colab.research.google.com/#create=true).

üêò *If you know what you are doing, you are also welcome to use any `python` distribution, such as [Jupyter](https://jupyter.org/), [Anaconda](https://www.anaconda.com/) or [PyCharm](https://www.jetbrains.com/pycharm/).

ü¶è **If you *really* know what you are doing, just use the [`datascience-notebook`](https://hub.docker.com/r/jupyter/datascience-notebook) [Docker](https://www.docker.com/) image. Also, this course might not be for you üôÉ

## üîÆ Tools & Software
We don't require any prior downloaded software for the masterclass (* You may use *any* text editor already installed on your system. You might already have [Sublime Text](https://www.sublimetext.com/), [Notepad++](https://notepad-plus-plus.org/) or [Atom](https://github.com/atom/atom/releases/tag/v1.60.0) on your system. The default *Notepad* in Windows is inadequate, as it is difficult to  format indents in it. However, we will conduct the common coding experience for the class in [*VSCode*](https://code.visualstudio.com/)). It helps us speed up things on the day if you do some preparation before the class:

- Take a look at [Visual Studio Code (*VSCode*) Desktop](https://code.visualstudio.com/docs)
- Take a look at the [Vega-Lite Visualisation Grammar](https://vega.github.io/vega-lite/) and the [Vega-Lite Example Gallery](https://vega.github.io/vega-lite/examples/)
  - Vega-Lite is based on the [Grammar of Graphics](https://www.springer.com/gp/book/9780387245447) by [Leland Wilkinson](https://en.wikipedia.org/wiki/Leland_Wilkinson), which is the basis of the [ggplot2](https://ggplot2.tidyverse.org/) package in `R` and the [Altair](https://altair-viz.github.io/) package in `python`. It is also the basis of the [Vega](https://vega.github.io/vega/) visualisation grammars, which [Vega-Lite](https://vega.github.io/vega-lite/) is a simplification of.

#### üéÆ Action points

- [Download and install *VSCode*](https://code.visualstudio.com/) for your operating system
- Install the [Live Server](https://marketplace.visualstudio.com/items?itemName=ritwickdey.LiveServer) plugin for *VSCode*  
- Test that the [Simple Bar Chart](https://vega.github.io/editor/#/examples/vega-lite/bar) example in the [Vega Editor](https://vega.github.io/editor/) works in your browser
  - If you get blank screen at first, try clicking on the `Fulscreen` button in the top right corner of the right pane of the editor

üêò *If you know what you are doing, you are welcome to use *any* text editor, provided that you also know how to establish a live server with `ptyhon`, such as [`SimpleHTTPServer`](https://www.pythonforbeginners.com/modules-in-python/how-to-use-simplehttpserver) or [`wutch`](https://www.linkedin.com/pulse/introducing-wutch-python-based-live-server-vagiz-duseev/).  
ü¶è *If you *really* know what you are doing, you are also welcome to skip the these steps and use an all-in-browser development environment like [*Codepen*](https://codepen.io/)

## üìä Datasets
**BYOD: We encourage you to Bring Your Own Data to the masterclass**.   
It can be data about everything, the financial report from the the last quarter or your sales logbook from your small coffee shop. It can be in any format `CSV, Excel, Stata, Matlab, JSON, etc.`  - or even just a table from a website, up to a cumbersome `API` call, we'll work with it.


If you want to look beyond, these data repositories are widely used by the community  
- https://huggingface.co/datasets  
- https://visualdata.io/discovery  
- https://paperswithcode.com/datasets  

#### üéÆ Action points

- If you **BYOD**, the	targeted complexity should be around `1000 data points` in at least `3 dimensions`. Say you have a small shop and you have sales data about `3` products ‚Äì this counts as `3` dimensions: the `sales value` (time series), the `time` (record date) and the `product` (name). Even better if you have this for different `cities` ‚Äì a `4`th dimension.

üêò *If you know what you are doing, convert your data into `JSON` format or just ping us the link to **any `API`** that you would like to explore a day before the class.  

ü¶è If you *really* know what you are doing, send us a link to your `*.ipynb` file or *Colab notebook* with any questions related to it a day before the class.

### Dataset Finders
 
Similar to how [Google Scholar](https://scholar.google.com/) works, [Google Dataset Search](https://toolbox.google.com/datasetsearch) lets you find datasets wherever they are hosted, whether it‚Äôs a publisher‚Äôs site, a digital library, or an author‚Äôs web page. It‚Äôs a phenomenal dataset finder, and it contains over 25 million datasets.

[Kaggle](https://www.kaggle.com/) provides a vast container of datasets, sufficient for the enthusiast to the expert.

The [UCI Machine Learning Repository](https://archive.ics.uci.edu/) at [UCI](https://www.uci.edu/) provides an up to date resource for open-source datasets.

[VisualData](https://www.visualdata.io/): Discover computer vision datasets by category; it allows searchable queries.

[CMU Libraries](https://guides.library.cmu.edu/machine-learning/datasets
)): Discover high-quality datasets thanks to the collection of Huajin Wang, at [CMU](https://www.cmu.edu/).

The [The Big Bad NLP Database](https://datasets.quantumstat.com/) contains datasets for various natural language processing tasks, created and curated by [Quantum Stat](https://quantumstat.com/).

Even more:  
[V7 | Alberto Rizzoli](https://www.v7labs.com/blog/best-free-datasets-for-machine-learning)  
[TowardsAI | Stacy Stanford, Roberto Iriondo, Pratik Shukla](https://pub.towardsai.net/best-datasets-for-machine-learning-data-science-computer-vision-nlp-ai-c9541058cf4f)  

#### üî¥ ECO Data Guidelines 
While all of our chart data are published under their respective article subfolders in **[ECOvisualisations](https://github.com/EconomicsObservatory/ecovisualisations)**, we also operate the [Economics Observatory Data Hub](https://www.economicsobservatory.com/data-hub), where you will find interactive tools and visualisations to easily load data from a number of sources in a unified format. Whenever possible, we try to follow a [TIDY](http://vita.had.co.nz/papers/tidy-data.pdf) format and you can read about our data zen in [**üìêdata guidelines**](https://github.com/EconomicsObservatory/ECOdataHUB/tree/main/guidelines). 

## üöÄ Takeaways

### 1.  Personal webpage
- GitHub account with a repository created to serve as your personal webpage, configured, styled and formatted
### 2. Data portfolio
- `3` interactive data visualisations including one chart with an interactive element and another one with *live* data served from an API or scraped from a website.
### 3. A new skillset
- The language of data *is* visualisation and by the end of this course you will have learnt how to introduce yourself in this new language.



{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MVfixlVBK5we"
      },
      "source": [
        "**Data Science - web scraper 3**\n",
        "\n",
        "Aim of the file:\n",
        "\n",
        "1.   Scrape multiple sites with a similar URL.\n",
        "2.   Do this efficiently by running a loop over an array.\n",
        "3.   Collect togeter the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "r-JSinApK49d"
      },
      "outputs": [],
      "source": [
        "# // 1.  Import packages that we need:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# // Web scraping: \n",
        "import requests\n",
        "import string\n",
        "from bs4 import BeautifulSoup\n",
        "# // OS. Sometimes need this for finding working directory:\n",
        "import os\n",
        "# ////////////////////////////////////////////////////////////////"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YH5WjG6IPVr7"
      },
      "source": [
        "Introduction: using a base URL and injecting a series of stock tickers into it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh8EIq2_PVXs",
        "outputId": "5e8766b2-5a2c-495f-e3cf-386cabe4c026"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([b'https://www.google.com/finance/quote/LLOY:LON',\n",
              "       b'https://www.google.com/finance/quote/NWG:LON',\n",
              "       b'https://www.google.com/finance/quote/BARC:LON',\n",
              "       b'https://www.google.com/finance/quote/HSBA:LON',\n",
              "       b'https://www.google.com/finance/quote/STAN:LON',\n",
              "       b'https://www.google.com/finance/quote/VMUK:LON'], dtype='|S50')"
            ]
          },
          "execution_count": 4,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# // Set the base URL: \n",
        "url_base = \"https://www.google.com/finance/quote/{}:LON\"\n",
        "\n",
        "# // Add an array of tickers, for major UK banks: \n",
        "tickers = ['LLOY', 'NWG', 'BARC', 'HSBA', 'STAN', 'VMUK']\n",
        "\n",
        "# // Create an empty array that we are going to fill, base it on the length of the tickers array\n",
        "length = len(tickers)\n",
        "urls = np.empty(length, dtype='S50')\n",
        "\n",
        "# // Loop across this array:\n",
        "for t in tickers:\n",
        "   # // Put the particular ticker into the base URL \n",
        "   stockURL = url_base.format(t)\n",
        "   # // Find the index value of this particular ticker.\n",
        "   i = tickers.index(t)\n",
        "   # // Fill the empty url, at the given index value, with the full url for this ticker\n",
        "   urls[i] = stockURL\n",
        "\n",
        "# // Print out the urls that we have   \n",
        "urls"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "f5wu9mFuSO2e"
      },
      "source": [
        "Using this in a full example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YVCVVxY3SMqu"
      },
      "outputs": [],
      "source": [
        "# // Set the base url:\n",
        "url_base = \"https://www.google.com/finance/quote/{}:LON\"\n",
        "\n",
        "# // Pick the letters that we want to inject into this url:\n",
        "tickers = ['LLOY', 'NWG', 'BARC', 'HSBA', 'STAN', 'VMUK']\n",
        "\n",
        "# // Create an empty array that is going to house the results\n",
        "# // We need to tell Python this array needs to be able to hold objects, hence dtype=object.\n",
        "# // This is becuase we are not going to put just one number, or one piece of string into position in the array\n",
        "# // Rather, each part of this array is going to be an array with the individual scrpaing results:\n",
        "data = np.empty(length, dtype='object')\n",
        "\n",
        "# // Begin a loop, dealing with this tickers one by one:\n",
        "for t in tickers:\n",
        "   \n",
        "   # // Return the index number of the thing we are working with:\n",
        "   s = tickers.index(t)\n",
        "   \n",
        "   # // Build the URL for this iteration of the loop:\n",
        "   URL = url_base.format(t)\n",
        "   \n",
        "   # // Request the html from the URL:\n",
        "   html = requests.get(URL)\n",
        "   \n",
        "   # // Get the soup of this page\n",
        "   soup = BeautifulSoup(html.content, 'html.parser')\n",
        "   \n",
        "   # // Now get what we want from the page: \n",
        "   name = soup.find_all(\"h1\")\n",
        "   price = soup.find_all(\"div\", class_=\"YMlKec fxKbKc\")\n",
        "   ticker = soup.find_all(\"div\", class_=\"COaKTb OTVmSe\")\n",
        "   change = soup.find_all(\"div\", class_=\"JwB6zf\")\n",
        "   \n",
        "   name = name[0].text\n",
        "   price = price[0].text\n",
        "   change = change[0].text\n",
        "   \n",
        "   # // Group together:\n",
        "   results = [t, name, price, change]\n",
        "   \n",
        "   # // Sense check: print out what we have on this point in the loop:\n",
        "   s\n",
        "   t\n",
        "   results\n",
        "\n",
        "   # // Find the index value of this particular ticker.\n",
        "   i = tickers.index(t)\n",
        "   \n",
        "   # // Fill these results in to a master array of results:\n",
        "   # // Fill the empty url, at the given index value, with the full url for this ticker\n",
        "   data[i] = results   "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GKjtke1Gfxom"
      },
      "source": [
        "Now examine what we have, and how we can retrive various parts of it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBHqsYyLdUx6",
        "outputId": "572b76a4-53c4-4d0b-c83e-6e8e063fc765"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([list(['LLOY', 'Lloyds Banking Group PLC', 'GBX\\xa046.24', '0.00%']),\n",
              "       list(['NWG', 'Natwest Group PLC', 'GBX\\xa0213.00', '0.00%']),\n",
              "       list(['BARC', 'Barclays PLC', 'GBX\\xa0181.40', '0.00%']),\n",
              "       list(['HSBA', 'HSBC Holdings plc', 'GBX\\xa0403.95', '0.00%']),\n",
              "       list(['STAN', 'Standard Chartered PLC', 'GBX\\xa0454.20', '0.00%']),\n",
              "       list(['VMUK', 'Virgin Money UK PLC', 'GBX\\xa0200.70', '0.00%'])],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 13,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUhqQIFcf3W9",
        "outputId": "fe53dc72-3188-4bca-b9be-ed7f3f198ba8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['NWG', 'Natwest Group PLC', 'GBX\\xa0213.00', '0.00%']"
            ]
          },
          "execution_count": 14,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fM2k5LZTf3KV",
        "outputId": "dbd11f7f-654e-4e21-f0af-b0738cbad2dd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'GBX\\xa046.24'"
            ]
          },
          "execution_count": 15,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[0][2]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "firstScraper.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

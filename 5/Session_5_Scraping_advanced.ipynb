{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RUSEHd29h6X"
      },
      "source": [
        "# Scraping the HTML source (advanced)\n",
        "\n",
        "Scraping HTML tables is easy, but sometimes we want to access data that isn't as nicely formatted. For example:\n",
        "\n",
        "- **Prices**: you might want data on a type of product or from a shop\n",
        "- **Weather**: maybe you want to automate the collection of weather data from the Met office or weather.com\n",
        "- **News and Media**: Scraping headlines and summaries can tell you about current affairs\n",
        "\n",
        "In this example, we will scrape the Economics Observatory website to collect the latest article names.\n",
        "\n",
        "## Investigating the webpage\n",
        "\n",
        "Before writing any code, let's take a look at the webpage.\n",
        "\n",
        "<img\n",
        "style=\"max-height: 250px;\n",
        "    width: auto;\" src=\"https://raw.githubusercontent.com/jhellingsdata/RADataHub/main/misc/Masterclass/section%205/images/eco_website.png\"> </img>\n",
        "\n",
        "We want to extract a list of article titles, such as \"What do we know about labour market power in the UK?\". To do this, we need to know where they appear in the HTML and how they are defined. By using inspect-element (right/ctrl click), we can see the HTML code that creates the titles.\n",
        "\n",
        "<img\n",
        "style=\"max-height: 250px;\n",
        "    width: auto;\" src=\"https://raw.githubusercontent.com/jhellingsdata/RADataHub/main/misc/Masterclass/section%205/images/inspect_element.png\"> </img>\n",
        "\n",
        "Here we can see that article titles have the class \"home__blocks-item-title\". We'll use this information to extract just the article titles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuCxs4izFLQD"
      },
      "source": [
        "## Scraping the page\n",
        "\n",
        "First, we'll download the HTML which defines the page, using the requests module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bgwjVswX9hJe"
      },
      "outputs": [],
      "source": [
        "req = requests.get(\"https://www.economicsobservatory.com\") # Make a request to the ECO home-page\n",
        "page_html = req.text # store the HTML in page_html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_nGUpFyDYcj"
      },
      "source": [
        "Now we have the page's source stored in {{page_html}}. Next we're going to use a module called BeautifulSoup to turn this text into a representation of the page we can interact with. We'll store this in a variable called {{soup}}."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4kTtbNFfDzXS"
      },
      "outputs": [],
      "source": [
        "soup = BeautifulSoup(page_html, 'html.parser') # Create a BeautifulSoup object to interact with the page's HTML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vGCAMSqGiS2"
      },
      "source": [
        "Now we'll look for article titles by searching for elements with the class \"home__blocks-item-title\" which we identified above.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJHYgoQSGiCM",
        "outputId": "92357eed-911a-441c-9c22-80be19915d0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Is work in the UK becoming more insecure?',\n",
              " 'What do we know about labour market power in the UK?',\n",
              " 'How can we reduce gender gaps in mathematics education?',\n",
              " 'How have minorities been treated by the UK’s judicial system?',\n",
              " 'How are plastics harming marine ecosystems?',\n",
              " 'Read the latest edition of our magazine here',\n",
              " 'How might house prices affect workers’ productivity in OECD economies?',\n",
              " 'Youth custody: who ends up there and how does it affect their later lives?',\n",
              " 'Central Bank Independence by Continent',\n",
              " 'The UK’s productivity gap: what did it look like twenty years ago?',\n",
              " 'Slow growing',\n",
              " 'Could a new policy institution help solve the UK’s productivity problem?',\n",
              " 'Which investments in human capital will boost productivity growth?',\n",
              " 'What’s worth reading over the 2023 holiday season?']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "article_title_elements = soup.find_all(class_=\"home__blocks-item-title\") # Find all elements with the class \"home__blocks-item-title\"\n",
        "article_titles = [element.text for element in article_title_elements] # Extract the text from each element\n",
        "article_titles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also care about the taglines/'teasers' of each article.\n",
        "\n",
        "These are contained in \\<spans\\> and \\<p\\> tags contained in divs with the class \"home__blocks-item-teaser display\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The increase in zero-hour contracts and the emergence of the gig economy over the past decade have raised concerns that working life is becoming less secure. Evidence suggests that while the share of workers experiencing insecure work has not gone up, some groups are more at risk.',\n",
              " 'Disparate treatment of minorities by the judicial system is not a construct of modern institutions. Irish defendants and victims faced harsher treatment and outcomes at London’s Old Bailey in the 19th century. Lessons from this period can help to inform criminal justice policy today.',\n",
              " 'The oceans have become a waste-sink for plastics—just like the atmosphere is for greenhouse gas emissions. A higher carbon price may help tackle both problems.',\n",
              " 'Higher house prices may be partly to blame for the sluggish growth of labour productivity in the OECD countries in recent decades. The adverse impact seems to be less severe in more complex economies – those that produce a greater diversity of products based on specialised know-how.',\n",
              " 'There are severe long-term consequences for young people in the UK who spend time in youth custody, the majority of whom are boys. Those with very low grades, in special education facilities and with additional educational needs are also more vulnerable to ending up in youth custody.',\n",
              " 'How to boost UK productivity growth has long been a central concern of economic researchers and policy-makers. A report written twenty years ago highlights the continuing challenges of achieving that ambition, including the key roles of competition, investment, skills, innovation and technology.',\n",
              " 'Reigniting productivity growth in the UK requires greater investment and better coordination of policy. An effective strategy should address inequalities across the country, as well as considering the institutions, skills and technologies needed to bridge the gap with comparable advanced economies.',\n",
              " 'Developing people’s knowledge and skills – their ‘human capital’ – is thought to be critical for improving productivity and sustaining economic growth. Empirical research suggests this link is surprisingly dubious, but measurement challenges may help explain this.',\n",
              " 'The lead editors of the Economics Observatory have shared their book recommendations for the holidays. Many of this year’s suggested reads have a historical focus, but they also reflect some of the big challenges we face today.']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# find all divs with the class \"home__blocks-item-teaser display\"\n",
        "tagline_divs = soup.find_all(class_=\"home__blocks-item-teaser display\")\n",
        "# get all the <p> tags from the tagline_divs\n",
        "taglines = [div.find(\"p\") for div in tagline_divs]\n",
        "# extract the text from each tag\n",
        "tagline_texts = [tagline.text for tagline in taglines]\n",
        "tagline_texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Dvhz5-NG5O0"
      },
      "source": [
        "And where from here?\n",
        "We now have a list of articles, how could this be useful?\n",
        "\n",
        "- **Automated News Roundups**: you could write code to collect news titles each day to produce a daily roundup\n",
        "- **Sentiment Analysis**: If you scale up the data collection, you could perform [sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis) to learn about the emotional valience of news stories.\n",
        "\n",
        "### Making a Chart: Term Frequencies\n",
        "\n",
        "Today, we can make a chart of term frequencies from the headlines. This will tell us about the topics covered by the website.\n",
        "\n",
        "To do this, we will:\n",
        "\n",
        "1. Define a list of common words to avoid (e.g. \"the\", \"how\", \"should\")\n",
        "2. Work out how many times each word appears, excluding the common words\n",
        "3. Save our data\n",
        "\n",
        "#### 1: Making a list of common words\n",
        "\n",
        "Thankfully, someone has already defined a list of common words [here](https://raw.githubusercontent.com/6/stopwords-json/master/dist/en.json). We can download this list to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HwZ5OdobUhMH"
      },
      "outputs": [],
      "source": [
        "# downloading the list of common words into a list\n",
        "common_words = requests.get(\"https://raw.githubusercontent.com/6/stopwords-json/master/dist/en.json\").json()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqhgvmfTUkbg"
      },
      "source": [
        "#### 2: Count How many Times each word appears"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L09lieBHjTr",
        "outputId": "220310eb-1840-4b36-b6d7-8f99dd5f9113"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'work': 2,\n",
              " 'uk': 4,\n",
              " 'labour': 2,\n",
              " 'market': 1,\n",
              " 'power': 1,\n",
              " 'reduce': 1,\n",
              " 'gender': 1,\n",
              " 'gaps': 1,\n",
              " 'mathematics': 1,\n",
              " 'minorities': 2,\n",
              " 'treated': 1,\n",
              " 'judicial': 2,\n",
              " 'plastics': 1,\n",
              " 'harming': 1,\n",
              " 'marine': 1,\n",
              " 'read': 1,\n",
              " 'latest': 1,\n",
              " 'edition': 1,\n",
              " 'magazine': 1,\n",
              " 'house': 2,\n",
              " 'prices': 2,\n",
              " 'affect': 2,\n",
              " 'productivity': 8,\n",
              " 'oecd': 2,\n",
              " 'youth': 3,\n",
              " 'ends': 1,\n",
              " 'central': 2,\n",
              " 'bank': 1,\n",
              " 'independence': 1,\n",
              " 'continent': 1,\n",
              " 'twenty': 2,\n",
              " 'years': 2,\n",
              " 'slow': 1,\n",
              " 'growing': 1,\n",
              " 'policy': 2,\n",
              " 'institution': 1,\n",
              " 'solve': 1,\n",
              " 'investments': 1,\n",
              " 'human': 1,\n",
              " 'capital': 1,\n",
              " 'boost': 2,\n",
              " 'worth': 1,\n",
              " 'reading': 1,\n",
              " 'holiday': 1,\n",
              " 'increase': 1,\n",
              " 'contracts': 1,\n",
              " 'emergence': 1,\n",
              " 'gig': 1,\n",
              " 'economy': 1,\n",
              " 'past': 1,\n",
              " 'decade': 1,\n",
              " 'raised': 1,\n",
              " 'concerns': 1,\n",
              " 'working': 1,\n",
              " 'life': 1,\n",
              " 'evidence': 1,\n",
              " 'suggests': 2,\n",
              " 'share': 1,\n",
              " 'workers': 1,\n",
              " 'experiencing': 1,\n",
              " 'insecure': 1,\n",
              " 'groups': 1,\n",
              " 'disparate': 1,\n",
              " 'treatment': 2,\n",
              " 'system': 1,\n",
              " 'construct': 1,\n",
              " 'modern': 1,\n",
              " 'irish': 1,\n",
              " 'defendants': 1,\n",
              " 'victims': 1,\n",
              " 'faced': 1,\n",
              " 'harsher': 1,\n",
              " 'outcomes': 1,\n",
              " 'bailey': 1,\n",
              " 'lessons': 1,\n",
              " 'period': 1,\n",
              " 'inform': 1,\n",
              " 'criminal': 1,\n",
              " 'justice': 1,\n",
              " 'oceans': 1,\n",
              " 'atmosphere': 1,\n",
              " 'greenhouse': 1,\n",
              " 'gas': 1,\n",
              " 'higher': 2,\n",
              " 'carbon': 1,\n",
              " 'price': 1,\n",
              " 'tackle': 1,\n",
              " 'partly': 1,\n",
              " 'blame': 1,\n",
              " 'sluggish': 1,\n",
              " 'growth': 3,\n",
              " 'countries': 1,\n",
              " 'recent': 1,\n",
              " 'adverse': 1,\n",
              " 'impact': 1,\n",
              " 'severe': 2,\n",
              " 'complex': 1,\n",
              " 'economies': 1,\n",
              " 'produce': 1,\n",
              " 'greater': 2,\n",
              " 'diversity': 1,\n",
              " 'products': 1,\n",
              " 'based': 1,\n",
              " 'specialised': 1,\n",
              " 'consequences': 1,\n",
              " 'young': 1,\n",
              " 'people': 1,\n",
              " 'spend': 1,\n",
              " 'time': 1,\n",
              " 'majority': 1,\n",
              " 'low': 1,\n",
              " 'special': 1,\n",
              " 'education': 1,\n",
              " 'facilities': 1,\n",
              " 'additional': 1,\n",
              " 'educational': 1,\n",
              " 'vulnerable': 1,\n",
              " 'ending': 1,\n",
              " 'long': 1,\n",
              " 'concern': 1,\n",
              " 'economic': 2,\n",
              " 'researchers': 1,\n",
              " 'report': 1,\n",
              " 'written': 1,\n",
              " 'ago': 1,\n",
              " 'highlights': 1,\n",
              " 'continuing': 1,\n",
              " 'challenges': 3,\n",
              " 'achieving': 1,\n",
              " 'including': 1,\n",
              " 'key': 1,\n",
              " 'roles': 1,\n",
              " 'innovation': 1,\n",
              " 'reigniting': 1,\n",
              " 'requires': 1,\n",
              " 'investment': 1,\n",
              " 'coordination': 1,\n",
              " 'effective': 1,\n",
              " 'strategy': 1,\n",
              " 'address': 1,\n",
              " 'inequalities': 1,\n",
              " 'skills': 2,\n",
              " 'technologies': 1,\n",
              " 'needed': 1,\n",
              " 'bridge': 1,\n",
              " 'gap': 1,\n",
              " 'comparable': 1,\n",
              " 'advanced': 1,\n",
              " 'developing': 1,\n",
              " 'knowledge': 1,\n",
              " 'thought': 1,\n",
              " 'critical': 1,\n",
              " 'improving': 1,\n",
              " 'sustaining': 1,\n",
              " 'empirical': 1,\n",
              " 'research': 1,\n",
              " 'link': 1,\n",
              " 'surprisingly': 1,\n",
              " 'measurement': 1,\n",
              " 'explain': 1,\n",
              " 'lead': 1,\n",
              " 'editors': 1,\n",
              " 'economics': 1,\n",
              " 'observatory': 1,\n",
              " 'shared': 1,\n",
              " 'book': 1,\n",
              " 'recommendations': 1,\n",
              " 'suggested': 1,\n",
              " 'reads': 1,\n",
              " 'historical': 1,\n",
              " 'reflect': 1,\n",
              " 'big': 1,\n",
              " 'face': 1}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# we'll store how many times each word appears in words\n",
        "words = {}\n",
        "\n",
        "# using a loop to go through every article title and tagline\n",
        "for text in article_titles+tagline_texts:\n",
        "  text = text.lower() # making it lowercase\n",
        "  for word in text.split():\n",
        "    if word in common_words or not word.isalpha():\n",
        "      continue # if this word is a common word (e.g. \"the\"), skip it\n",
        "    if word in words: # if we've already seen this word, just increase the count\n",
        "      words[word] += 1\n",
        "    else:\n",
        "      words[word] = 1\n",
        "\n",
        "words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3: Saving the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame(words.items(), columns=[\"word\", \"count\"]) # Create a DataFrame from the words dictionary\n",
        "df = df.sort_values(\"count\", ascending=False).head(10) # Sort the DataFrame by count and take the top 10\n",
        "df.to_csv(\"top_words.csv\", index=False) # Save the DataFrame to a CSV file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_qYPBYhTO41"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpbiCiIFTgg4",
        "outputId": "a8baec72-06bc-4bca-c3f8-98c2b3d7b70b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"–\".isalpha()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3HalFYETk6Y",
        "outputId": "400b10c5-31cd-4088-eb64-db99282e7813"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['a',\n",
              " \"a's\",\n",
              " 'able',\n",
              " 'about',\n",
              " 'above',\n",
              " 'according',\n",
              " 'accordingly',\n",
              " 'across',\n",
              " 'actually',\n",
              " 'after',\n",
              " 'afterwards',\n",
              " 'again',\n",
              " 'against',\n",
              " \"ain't\",\n",
              " 'all',\n",
              " 'allow',\n",
              " 'allows',\n",
              " 'almost',\n",
              " 'alone',\n",
              " 'along',\n",
              " 'already',\n",
              " 'also',\n",
              " 'although',\n",
              " 'always',\n",
              " 'am',\n",
              " 'among',\n",
              " 'amongst',\n",
              " 'an',\n",
              " 'and',\n",
              " 'another',\n",
              " 'any',\n",
              " 'anybody',\n",
              " 'anyhow',\n",
              " 'anyone',\n",
              " 'anything',\n",
              " 'anyway',\n",
              " 'anyways',\n",
              " 'anywhere',\n",
              " 'apart',\n",
              " 'appear',\n",
              " 'appreciate',\n",
              " 'appropriate',\n",
              " 'are',\n",
              " \"aren't\",\n",
              " 'around',\n",
              " 'as',\n",
              " 'aside',\n",
              " 'ask',\n",
              " 'asking',\n",
              " 'associated',\n",
              " 'at',\n",
              " 'available',\n",
              " 'away',\n",
              " 'awfully',\n",
              " 'b',\n",
              " 'be',\n",
              " 'became',\n",
              " 'because',\n",
              " 'become',\n",
              " 'becomes',\n",
              " 'becoming',\n",
              " 'been',\n",
              " 'before',\n",
              " 'beforehand',\n",
              " 'behind',\n",
              " 'being',\n",
              " 'believe',\n",
              " 'below',\n",
              " 'beside',\n",
              " 'besides',\n",
              " 'best',\n",
              " 'better',\n",
              " 'between',\n",
              " 'beyond',\n",
              " 'both',\n",
              " 'brief',\n",
              " 'but',\n",
              " 'by',\n",
              " 'c',\n",
              " \"c'mon\",\n",
              " \"c's\",\n",
              " 'came',\n",
              " 'can',\n",
              " \"can't\",\n",
              " 'cannot',\n",
              " 'cant',\n",
              " 'cause',\n",
              " 'causes',\n",
              " 'certain',\n",
              " 'certainly',\n",
              " 'changes',\n",
              " 'clearly',\n",
              " 'co',\n",
              " 'com',\n",
              " 'come',\n",
              " 'comes',\n",
              " 'concerning',\n",
              " 'consequently',\n",
              " 'consider',\n",
              " 'considering',\n",
              " 'contain',\n",
              " 'containing',\n",
              " 'contains',\n",
              " 'corresponding',\n",
              " 'could',\n",
              " \"couldn't\",\n",
              " 'course',\n",
              " 'currently',\n",
              " 'd',\n",
              " 'definitely',\n",
              " 'described',\n",
              " 'despite',\n",
              " 'did',\n",
              " \"didn't\",\n",
              " 'different',\n",
              " 'do',\n",
              " 'does',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " \"don't\",\n",
              " 'done',\n",
              " 'down',\n",
              " 'downwards',\n",
              " 'during',\n",
              " 'e',\n",
              " 'each',\n",
              " 'edu',\n",
              " 'eg',\n",
              " 'eight',\n",
              " 'either',\n",
              " 'else',\n",
              " 'elsewhere',\n",
              " 'enough',\n",
              " 'entirely',\n",
              " 'especially',\n",
              " 'et',\n",
              " 'etc',\n",
              " 'even',\n",
              " 'ever',\n",
              " 'every',\n",
              " 'everybody',\n",
              " 'everyone',\n",
              " 'everything',\n",
              " 'everywhere',\n",
              " 'ex',\n",
              " 'exactly',\n",
              " 'example',\n",
              " 'except',\n",
              " 'f',\n",
              " 'far',\n",
              " 'few',\n",
              " 'fifth',\n",
              " 'first',\n",
              " 'five',\n",
              " 'followed',\n",
              " 'following',\n",
              " 'follows',\n",
              " 'for',\n",
              " 'former',\n",
              " 'formerly',\n",
              " 'forth',\n",
              " 'four',\n",
              " 'from',\n",
              " 'further',\n",
              " 'furthermore',\n",
              " 'g',\n",
              " 'get',\n",
              " 'gets',\n",
              " 'getting',\n",
              " 'given',\n",
              " 'gives',\n",
              " 'go',\n",
              " 'goes',\n",
              " 'going',\n",
              " 'gone',\n",
              " 'got',\n",
              " 'gotten',\n",
              " 'greetings',\n",
              " 'h',\n",
              " 'had',\n",
              " \"hadn't\",\n",
              " 'happens',\n",
              " 'hardly',\n",
              " 'has',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " \"he's\",\n",
              " 'hello',\n",
              " 'help',\n",
              " 'hence',\n",
              " 'her',\n",
              " 'here',\n",
              " \"here's\",\n",
              " 'hereafter',\n",
              " 'hereby',\n",
              " 'herein',\n",
              " 'hereupon',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'hi',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'hither',\n",
              " 'hopefully',\n",
              " 'how',\n",
              " 'howbeit',\n",
              " 'however',\n",
              " 'i',\n",
              " \"i'd\",\n",
              " \"i'll\",\n",
              " \"i'm\",\n",
              " \"i've\",\n",
              " 'ie',\n",
              " 'if',\n",
              " 'ignored',\n",
              " 'immediate',\n",
              " 'in',\n",
              " 'inasmuch',\n",
              " 'inc',\n",
              " 'indeed',\n",
              " 'indicate',\n",
              " 'indicated',\n",
              " 'indicates',\n",
              " 'inner',\n",
              " 'insofar',\n",
              " 'instead',\n",
              " 'into',\n",
              " 'inward',\n",
              " 'is',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it'd\",\n",
              " \"it'll\",\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'j',\n",
              " 'just',\n",
              " 'k',\n",
              " 'keep',\n",
              " 'keeps',\n",
              " 'kept',\n",
              " 'know',\n",
              " 'known',\n",
              " 'knows',\n",
              " 'l',\n",
              " 'last',\n",
              " 'lately',\n",
              " 'later',\n",
              " 'latter',\n",
              " 'latterly',\n",
              " 'least',\n",
              " 'less',\n",
              " 'lest',\n",
              " 'let',\n",
              " \"let's\",\n",
              " 'like',\n",
              " 'liked',\n",
              " 'likely',\n",
              " 'little',\n",
              " 'look',\n",
              " 'looking',\n",
              " 'looks',\n",
              " 'ltd',\n",
              " 'm',\n",
              " 'mainly',\n",
              " 'many',\n",
              " 'may',\n",
              " 'maybe',\n",
              " 'me',\n",
              " 'mean',\n",
              " 'meanwhile',\n",
              " 'merely',\n",
              " 'might',\n",
              " 'more',\n",
              " 'moreover',\n",
              " 'most',\n",
              " 'mostly',\n",
              " 'much',\n",
              " 'must',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'n',\n",
              " 'name',\n",
              " 'namely',\n",
              " 'nd',\n",
              " 'near',\n",
              " 'nearly',\n",
              " 'necessary',\n",
              " 'need',\n",
              " 'needs',\n",
              " 'neither',\n",
              " 'never',\n",
              " 'nevertheless',\n",
              " 'new',\n",
              " 'next',\n",
              " 'nine',\n",
              " 'no',\n",
              " 'nobody',\n",
              " 'non',\n",
              " 'none',\n",
              " 'noone',\n",
              " 'nor',\n",
              " 'normally',\n",
              " 'not',\n",
              " 'nothing',\n",
              " 'novel',\n",
              " 'now',\n",
              " 'nowhere',\n",
              " 'o',\n",
              " 'obviously',\n",
              " 'of',\n",
              " 'off',\n",
              " 'often',\n",
              " 'oh',\n",
              " 'ok',\n",
              " 'okay',\n",
              " 'old',\n",
              " 'on',\n",
              " 'once',\n",
              " 'one',\n",
              " 'ones',\n",
              " 'only',\n",
              " 'onto',\n",
              " 'or',\n",
              " 'other',\n",
              " 'others',\n",
              " 'otherwise',\n",
              " 'ought',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'outside',\n",
              " 'over',\n",
              " 'overall',\n",
              " 'own',\n",
              " 'p',\n",
              " 'particular',\n",
              " 'particularly',\n",
              " 'per',\n",
              " 'perhaps',\n",
              " 'placed',\n",
              " 'please',\n",
              " 'plus',\n",
              " 'possible',\n",
              " 'presumably',\n",
              " 'probably',\n",
              " 'provides',\n",
              " 'q',\n",
              " 'que',\n",
              " 'quite',\n",
              " 'qv',\n",
              " 'r',\n",
              " 'rather',\n",
              " 'rd',\n",
              " 're',\n",
              " 'really',\n",
              " 'reasonably',\n",
              " 'regarding',\n",
              " 'regardless',\n",
              " 'regards',\n",
              " 'relatively',\n",
              " 'respectively',\n",
              " 'right',\n",
              " 's',\n",
              " 'said',\n",
              " 'same',\n",
              " 'saw',\n",
              " 'say',\n",
              " 'saying',\n",
              " 'says',\n",
              " 'second',\n",
              " 'secondly',\n",
              " 'see',\n",
              " 'seeing',\n",
              " 'seem',\n",
              " 'seemed',\n",
              " 'seeming',\n",
              " 'seems',\n",
              " 'seen',\n",
              " 'self',\n",
              " 'selves',\n",
              " 'sensible',\n",
              " 'sent',\n",
              " 'serious',\n",
              " 'seriously',\n",
              " 'seven',\n",
              " 'several',\n",
              " 'shall',\n",
              " 'she',\n",
              " 'should',\n",
              " \"shouldn't\",\n",
              " 'since',\n",
              " 'six',\n",
              " 'so',\n",
              " 'some',\n",
              " 'somebody',\n",
              " 'somehow',\n",
              " 'someone',\n",
              " 'something',\n",
              " 'sometime',\n",
              " 'sometimes',\n",
              " 'somewhat',\n",
              " 'somewhere',\n",
              " 'soon',\n",
              " 'sorry',\n",
              " 'specified',\n",
              " 'specify',\n",
              " 'specifying',\n",
              " 'still',\n",
              " 'sub',\n",
              " 'such',\n",
              " 'sup',\n",
              " 'sure',\n",
              " 't',\n",
              " \"t's\",\n",
              " 'take',\n",
              " 'taken',\n",
              " 'tell',\n",
              " 'tends',\n",
              " 'th',\n",
              " 'than',\n",
              " 'thank',\n",
              " 'thanks',\n",
              " 'thanx',\n",
              " 'that',\n",
              " \"that's\",\n",
              " 'thats',\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'thence',\n",
              " 'there',\n",
              " \"there's\",\n",
              " 'thereafter',\n",
              " 'thereby',\n",
              " 'therefore',\n",
              " 'therein',\n",
              " 'theres',\n",
              " 'thereupon',\n",
              " 'these',\n",
              " 'they',\n",
              " \"they'd\",\n",
              " \"they'll\",\n",
              " \"they're\",\n",
              " \"they've\",\n",
              " 'think',\n",
              " 'third',\n",
              " 'this',\n",
              " 'thorough',\n",
              " 'thoroughly',\n",
              " 'those',\n",
              " 'though',\n",
              " 'three',\n",
              " 'through',\n",
              " 'throughout',\n",
              " 'thru',\n",
              " 'thus',\n",
              " 'to',\n",
              " 'together',\n",
              " 'too',\n",
              " 'took',\n",
              " 'toward',\n",
              " 'towards',\n",
              " 'tried',\n",
              " 'tries',\n",
              " 'truly',\n",
              " 'try',\n",
              " 'trying',\n",
              " 'twice',\n",
              " 'two',\n",
              " 'u',\n",
              " 'un',\n",
              " 'under',\n",
              " 'unfortunately',\n",
              " 'unless',\n",
              " 'unlikely',\n",
              " 'until',\n",
              " 'unto',\n",
              " 'up',\n",
              " 'upon',\n",
              " 'us',\n",
              " 'use',\n",
              " 'used',\n",
              " 'useful',\n",
              " 'uses',\n",
              " 'using',\n",
              " 'usually',\n",
              " 'uucp',\n",
              " 'v',\n",
              " 'value',\n",
              " 'various',\n",
              " 'very',\n",
              " 'via',\n",
              " 'viz',\n",
              " 'vs',\n",
              " 'w',\n",
              " 'want',\n",
              " 'wants',\n",
              " 'was',\n",
              " \"wasn't\",\n",
              " 'way',\n",
              " 'we',\n",
              " \"we'd\",\n",
              " \"we'll\",\n",
              " \"we're\",\n",
              " \"we've\",\n",
              " 'welcome',\n",
              " 'well',\n",
              " 'went',\n",
              " 'were',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " \"what's\",\n",
              " 'whatever',\n",
              " 'when',\n",
              " 'whence',\n",
              " 'whenever',\n",
              " 'where',\n",
              " \"where's\",\n",
              " 'whereafter',\n",
              " 'whereas',\n",
              " 'whereby',\n",
              " 'wherein',\n",
              " 'whereupon',\n",
              " 'wherever',\n",
              " 'whether',\n",
              " 'which',\n",
              " 'while',\n",
              " 'whither',\n",
              " 'who',\n",
              " \"who's\",\n",
              " 'whoever',\n",
              " 'whole',\n",
              " 'whom',\n",
              " 'whose',\n",
              " 'why',\n",
              " 'will',\n",
              " 'willing',\n",
              " 'wish',\n",
              " 'with',\n",
              " 'within',\n",
              " 'without',\n",
              " \"won't\",\n",
              " 'wonder',\n",
              " 'would',\n",
              " \"wouldn't\",\n",
              " 'x',\n",
              " 'y',\n",
              " 'yes',\n",
              " 'yet',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'z',\n",
              " 'zero']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "common_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DyfGc-7SybA",
        "outputId": "81c209d8-c027-41e9-d2d6-f51f79e73da0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'is': 1,\n",
              " 'work': 1,\n",
              " 'in': 5,\n",
              " 'the': 7,\n",
              " 'uk': 1,\n",
              " 'becoming': 1,\n",
              " 'more': 1,\n",
              " 'insecure?': 1,\n",
              " 'what': 2,\n",
              " 'do': 1,\n",
              " 'we': 2,\n",
              " 'know': 1,\n",
              " 'about': 1,\n",
              " 'labour': 1,\n",
              " 'market': 1,\n",
              " 'power': 1,\n",
              " 'uk?': 1,\n",
              " 'how': 5,\n",
              " 'can': 1,\n",
              " 'reduce': 1,\n",
              " 'gender': 1,\n",
              " 'gaps': 1,\n",
              " 'mathematics': 1,\n",
              " 'education?': 1,\n",
              " 'have': 1,\n",
              " 'minorities': 1,\n",
              " 'been': 1,\n",
              " 'treated': 1,\n",
              " 'by': 2,\n",
              " 'uk’s': 3,\n",
              " 'judicial': 1,\n",
              " 'system?': 1,\n",
              " 'are': 1,\n",
              " 'plastics': 1,\n",
              " 'harming': 1,\n",
              " 'marine': 1,\n",
              " 'ecosystems?': 1,\n",
              " 'read': 1,\n",
              " 'latest': 1,\n",
              " 'edition': 1,\n",
              " 'of': 1,\n",
              " 'our': 1,\n",
              " 'magazine': 1,\n",
              " 'here': 1,\n",
              " 'might': 1,\n",
              " 'house': 1,\n",
              " 'prices': 1,\n",
              " 'affect': 2,\n",
              " 'workers’': 1,\n",
              " 'productivity': 4,\n",
              " 'oecd': 1,\n",
              " 'economies?': 1,\n",
              " 'youth': 1,\n",
              " 'custody:': 1,\n",
              " 'who': 1,\n",
              " 'ends': 1,\n",
              " 'up': 1,\n",
              " 'there': 1,\n",
              " 'and': 1,\n",
              " 'does': 1,\n",
              " 'it': 2,\n",
              " 'their': 1,\n",
              " 'later': 1,\n",
              " 'lives?': 1,\n",
              " 'central': 1,\n",
              " 'bank': 1,\n",
              " 'independence': 1,\n",
              " 'continent': 1,\n",
              " 'gap:': 1,\n",
              " 'did': 1,\n",
              " 'look': 1,\n",
              " 'like': 1,\n",
              " 'twenty': 1,\n",
              " 'years': 1,\n",
              " 'ago?': 1,\n",
              " 'slow': 1,\n",
              " 'growing': 1,\n",
              " 'could': 1,\n",
              " 'a': 1,\n",
              " 'new': 1,\n",
              " 'policy': 1,\n",
              " 'institution': 1,\n",
              " 'help': 1,\n",
              " 'solve': 1,\n",
              " 'problem?': 1,\n",
              " 'which': 1,\n",
              " 'investments': 1,\n",
              " 'human': 1,\n",
              " 'capital': 1,\n",
              " 'will': 1,\n",
              " 'boost': 1,\n",
              " 'growth?': 1,\n",
              " 'what’s': 1,\n",
              " 'worth': 1,\n",
              " 'reading': 1,\n",
              " 'over': 1,\n",
              " '2023': 1,\n",
              " 'holiday': 1,\n",
              " 'season?': 1}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Y4WNqwggSL6g",
        "outputId": "faf40d5f-bbd9-49fa-e166-74f2dccb0d1d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'What’s worth reading over the 2023 holiday season?'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "title.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djl9eQr9SPhD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
